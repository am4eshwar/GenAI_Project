# -*- coding: utf-8 -*-
"""GenAI_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1omlawUQ1xLt47BUCMX-mD_aYAZz4Pm1A
"""

!pip install diffusers transformers accelerate scipy safetensors
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install streamlit pyngrok

from diffusers import StableDiffusionPipeline
import torch

# Set to "cuda" if you're using GPU runtime
device = "cuda"

# Load model correctly for CPU (or GPU if using "cuda")
pipe = StableDiffusionPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4",
    torch_dtype=torch.float32 if device == "cpu" else torch.float16,
    revision="fp16" if device == "cuda" else None
).to(device)

prompt = "a fantasy landscape with floating islands and waterfalls"

image = pipe(prompt).images[0]

image.save("output.png")
image.show()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from diffusers import StableDiffusionPipeline
# import torch
# 
# st.title("üñºÔ∏è Stable Diffusion Image Generator")
# 
# prompt = st.text_input("Enter your prompt", "")
# 
# if prompt:
#     with st.spinner("Generating..."):
#         device = "cuda"
#         pipe = StableDiffusionPipeline.from_pretrained(
#             "CompVis/stable-diffusion-v1-4",
#             torch_dtype=torch.float32
#         ).to(device)
# 
#         image = pipe(prompt).images[0]
#         st.image(image, caption=prompt)
#

from pyngrok import ngrok

# Paste your real token inside the quotes
ngrok.set_auth_token("2zs7GgfrAyl4J9cV0BUUF33NAfM_3J3AhuSqLKf3ooBGMkhsp")
# Set up the tunnel again after auth
public_url = ngrok.connect("http://localhost:8501")

print(f"Public URL: {public_url}")

# Start the Streamlit app
!streamlit run app.py
